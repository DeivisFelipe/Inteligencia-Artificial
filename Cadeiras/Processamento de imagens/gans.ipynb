{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gan de imagens 640x640 de 3 canais de cancer de pele\n",
    "# imagens /datasets/train/images\n",
    "path = '/datasets/train/images'\n",
    "\n",
    "# Discriminador\n",
    "def define_discriminator(in_shape=(640,640,3)):\n",
    "    model = Sequential()\n",
    "    # normal\n",
    "    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample\n",
    "    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Gerador\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    # foundation for 20x20 image\n",
    "    n_nodes = 128 * 20 * 20\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((20, 20, 128)))\n",
    "    # upsample to 40x40\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 80x80\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 160x160\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 320x320\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # output layer\n",
    "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
    "    return model \n",
    "\n",
    "# GAN\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add the discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# Carregar imagens\n",
    "def load_real_samples():\n",
    "    # pegar imagens\n",
    "    X = np.load(path)\n",
    "    # converter de int para float\n",
    "    X = X.astype('float32')\n",
    "    # escalar de -1 a 1\n",
    "    X = (X - 127.5) / 12\n",
    "    return X\n",
    "\n",
    "# Treina com todas as imagens\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # escolher imagens aleatorias\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # selecionar imagens\n",
    "    X = dataset[ix]\n",
    "    # gerar classe\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "# Gerar pontos no espaço latente\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # gerar pontos no espaço latente\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # redimensionar para o modelo\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# Usar o gerador para criar imagens falsas\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # gerar pontos no espaço latente\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # prever\n",
    "    X = g_model.predict(x_input)\n",
    "    # criar classe\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
